---
title: "Question 2: Detecting True Demand Growth in a Solar-Rich Energy System"
author: "Carlos Peralta"
format: html
jupyter: python3
execute:
  echo: true
  engine: jupyter
date: "7 August 2025"
date-modified: last-modified
lang: en
---

## Introduction

This notebook addresses Question 2 of the meteorological data scientist case study. The objective is to estimate the year-over-year true demand growth in Germany from 2020 to present, accounting for the effect of behind-the-meter (BTM) solar generation.

### Key Questions to Address

1.  How can we isolate the effect of BTM solar generation on observed demand?
2.  Can we estimate what demand would have been during solar hours without rooftop solar?
3.  What is the difference between projected demand and observed demand?
4.  How has BTM solar generation evolved from 2020 to present?
5.  What is the year-over-year growth in *true* demand?

In order to answer these quetions we will do some feature engineering and
then build multiple estimation methods based on weather (baseline), regression
and time series decomposition.


## Setup

```{python}
#| label: setup
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import holidays
from rich import print
import warnings
warnings.filterwarnings("ignore")

# Set plotting style
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

print("Libraries loaded successfully")
```

## Data Loading and Initial Exploration
We loads merge and prepares the data.

```{python}
#| label: load-data
# Load the three datasets for Question 2
demand_q2 = pd.read_csv("../data/germany_electricity_demand_observation_q2.csv", parse_dates=['DateTime'])
solar_q2 = pd.read_csv("../data/germany_solar_observation_q2.csv", parse_dates=['DateTime'])
atm_q2 = pd.read_csv("../data/germany_atm_features_q2.csv", parse_dates=['DateTime'])

# Merge all datasets
data_q2 = pd.merge(demand_q2, solar_q2, on="DateTime", how="inner")
data_q2 = pd.merge(data_q2, atm_q2, on="DateTime", how="inner")

print(f"Merged data shape: {data_q2.shape}")
print(f"Merged data range: {data_q2['DateTime'].min()} to {data_q2['DateTime'].max()}")
```

## Feature Engineering
In the following section we create a rich set of temporal and weather-related features, which are crucial for demand modeling.

```{python}
#| label: feature-engineering
def add_temporal_features(df):
    """Add comprehensive temporal features for analysis"""
    df = df.copy()
    
    # Basic time features
    df['year'] = df['DateTime'].dt.year
    df['month'] = df['DateTime'].dt.month
    df['day'] = df['DateTime'].dt.day
    df['hour'] = df['DateTime'].dt.hour
    df['dayofweek'] = df['DateTime'].dt.dayofweek
    df['dayofyear'] = df['DateTime'].dt.dayofyear
    df['quarter'] = df['DateTime'].dt.quarter
    
    # Season classification
    df['season'] = df['month'].map({
        12: 'Winter', 1: 'Winter', 2: 'Winter',
        3: 'Spring', 4: 'Spring', 5: 'Spring',
        6: 'Summer', 7: 'Summer', 8: 'Summer',
        9: 'Autumn', 10: 'Autumn', 11: 'Autumn'
    })
    
    # Solar hours classification (more conservative: 7 AM to 7 PM)
    df['is_solar_hours'] = ((df['hour'] >= 7) & (df['hour'] <= 19)).astype(int)
    df['is_peak_solar'] = ((df['hour'] >= 10) & (df['hour'] <= 14)).astype(int)
    
    # Weekend indicator
    df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)
    
    # Add German holiday calendar ---
    de_holidays = holidays.Germany(years=np.arange(2020, 2026))
    df['is_holiday'] = df['DateTime'].dt.date.astype('datetime64[ns]').isin(de_holidays).astype(int)
    
    # Treat holidays like weekends for modeling purposes
    df['is_workday'] = ((df['is_weekend'] == 0) & (df['is_holiday'] == 0)).astype(int)

    # Cyclical encoding for better model performance
    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
    df['dayofyear_sin'] = np.sin(2 * np.pi * df['dayofyear'] / 365)
    df['dayofyear_cos'] = np.cos(2 * np.pi * df['dayofyear'] / 365)
    
    return df

# Apply feature engineering
data_q2_expanded = add_temporal_features(data_q2)
print("Feature engineering completed.")
print(f"Number of holidays identified: {data_q2_expanded['is_holiday'].sum()}")
```

## BTM Solar Estimation Methods

### Method 1: Demand Gap Analysis

This method learns a "normal" demand pattern from hours with no solar generation and uses it to predict what demand *should have been* during solar hours. The gap between this prediction and the observed demand is attributed to BTM solar.

```{python}
#| label: method1
class DemandGapBTMEstimator:
    """
    Estimates BTM solar by modeling baseline demand from non-solar hours.
    """
    def __init__(self):
        self.demand_model = None
        self.scaler = None
        self.feature_names = [
            'temperature_2m', 'apparent_temperature', 'relative_humidity_2m',
            'hour_sin', 'hour_cos', 'dayofyear_sin', 'dayofyear_cos',
            'is_workday', 'year'
        ]
        
    def fit(self, data):
        """Fit a demand model exclusively on non-solar hour data."""
        # Train only on non-solar hours
        train_data = data[data['is_solar_hours'] == 0].copy()
        
        X_train = train_data[self.feature_names]
        y_train = train_data['demand']
        
        self.scaler = StandardScaler()
        X_train_scaled = self.scaler.fit_transform(X_train)
        
        # Use a robust RandomForest model
        self.demand_model = RandomForestRegressor(
            n_estimators=100, random_state=42, n_jobs=-1, min_samples_leaf=10
        )
        self.demand_model.fit(X_train_scaled, y_train)
        
    def estimate_btm_solar(self, data):
        """Estimate BTM solar as the gap between predicted and observed demand."""
        results = data.copy()
        
        X_all = results[self.feature_names]
        X_all_scaled = self.scaler.transform(X_all)
        
        # Predict what demand should have been across all hours
        predicted_baseline_demand = self.demand_model.predict(X_all_scaled)
        
        # The gap is the difference, floored at zero
        demand_gap = predicted_baseline_demand - results['demand']
        demand_gap = np.maximum(demand_gap, 0)
        
        # BTM solar only exists during solar hours
        results['btm_method1'] = 0.0
        solar_mask = results['is_solar_hours'] == 1
        results.loc[solar_mask, 'btm_method1'] = demand_gap[solar_mask]
        
        return results

# Apply Method 1
print("=== Method 1: Demand Gap Analysis ===")
estimator_m1 = DemandGapBTMEstimator()
estimator_m1.fit(data_q2_expanded)
results_m1 = estimator_m1.estimate_btm_solar(data_q2_expanded)

print("BTM Solar Estimation Summary (Method 1):")
print(results_m1.groupby('year')['btm_method1'].sum().round(2))
```

### Method 2: Unbiased Regression Decomposition

This method uses a simple Ridge regression model, trained only on non-solar hour data to prevent the model from learning the BTM-suppressed demand as "normal". 
This removes a possible source of bias.

```{python}
#| label: method2
class UnbiasedRegressionBTMEstimator:
    """
    Uses Ridge regression trained only on non-solar hours to estimate BTM.
    """
    def __init__(self):
        self.demand_model = None
        self.scaler = None
        self.feature_names = [
            'temperature_2m', 'apparent_temperature', 'relative_humidity_2m',
            'hour_sin', 'hour_cos', 'dayofyear_sin', 'dayofyear_cos',
            'is_workday', 'year'
        ]
        
    def fit(self, data):
        """Fit a Ridge regression model exclusively on non-solar hour data."""
        # Train only on non-solar hours ---
        train_data = data[data['is_solar_hours'] == 0].copy()
        
        X_train = train_data[self.feature_names]
        y_train = train_data['demand']
        
        self.scaler = StandardScaler()
        X_train_scaled = self.scaler.fit_transform(X_train)
        
        self.demand_model = Ridge(alpha=1.0, random_state=42)
        self.demand_model.fit(X_train_scaled, y_train)
        
    def estimate_btm_solar(self, data):
        """Estimate BTM solar as the gap between predicted and observed demand."""
        results = data.copy()
        
        X_all = results[self.feature_names]
        X_all_scaled = self.scaler.transform(X_all)
        
        predicted_baseline_demand = self.demand_model.predict(X_all_scaled)
        
        demand_gap = predicted_baseline_demand - results['demand']
        demand_gap = np.maximum(demand_gap, 0)
        
        results['btm_method2'] = 0.0
        solar_mask = results['is_solar_hours'] == 1
        results.loc[solar_mask, 'btm_method2'] = demand_gap[solar_mask]
        
        return results

# Apply Method 2
print("=== Method 2: Unbiased Regression Decomposition ===")
estimator_m2 = UnbiasedRegressionBTMEstimator()
estimator_m2.fit(data_q2_expanded)
results_m2 = estimator_m2.estimate_btm_solar(data_q2_expanded)

print("BTM Solar Estimation Summary (Method 2):")
print(results_m2.groupby('year')['btm_method2'].sum().round(2))
```

### Method 3: Time Series Decomposition 

This method looks at the diverging trends between solar and non-solar hour demand over time. 

```{python}
#| label: method3


import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score
from scipy.optimize import minimize
import warnings
warnings.filterwarnings("ignore")

def calculate_degree_days(temperature, heating_base=18, cooling_base=24):
    """
    Calculate heating and cooling degree days using standard methodology
    
    Parameters:
    -----------
    temperature : array-like
        Temperature values in Celsius
    heating_base : float
        Base temperature for heating degree days (default 18°C for Germany)
    cooling_base : float
        Base temperature for cooling degree days (default 24°C for Germany)
    
    Returns:
    --------
    hdd, cdd : tuple of arrays
        Heating and cooling degree days
    """
    temperature = np.array(temperature)  # Fix: ensure temperature is numpy array
    hdd = np.maximum(heating_base - temperature, 0)
    cdd = np.maximum(temperature - cooling_base, 0)
    return hdd, cdd

def find_optimal_base_temperatures(demand, temperature, test_range_heat=(15, 21), test_range_cool=(22, 28)):
    """
    Find optimal base temperatures using regression analysis
    
    Parameters:
    -----------
    demand : array-like
        Electricity demand values
    temperature : array-like
        Temperature values
    test_range_heat : tuple
        Range of heating base temperatures to test
    test_range_cool : tuple
        Range of cooling base temperatures to test
    
    Returns:
    --------
    best_bases : tuple
        Optimal (heating_base, cooling_base)
    best_r2 : float
        R-squared of best fit
    """
    best_r2 = 0
    best_bases = (18, 24)  # defaults
    
    for heat_base in range(test_range_heat[0], test_range_heat[1] + 1):
        for cool_base in range(test_range_cool[0], test_range_cool[1] + 1):
            hdd, cdd = calculate_degree_days(temperature, heat_base, cool_base)
            
            # Skip if no variation in degree days
            if np.std(hdd) < 0.1 and np.std(cdd) < 0.1:
                continue
                
            X = np.column_stack([hdd, cdd, np.ones(len(hdd))])  # include intercept
            
            try:
                model = LinearRegression(fit_intercept=False).fit(X, demand)
                r2 = model.score(X, demand)
                
                if r2 > best_r2:
                    best_r2 = r2
                    best_bases = (heat_base, cool_base)
            except:
                continue
    
    return best_bases, best_r2

def weather_normalize_demand_regression(demand, temperature, heating_base=None, cooling_base=None):
    """
    Weather normalize demand using regression-based degree day method
    
    Parameters:
    -----------
    demand : array-like
        Electricity demand values
    temperature : array-like
        Temperature values in Celsius
    heating_base : float, optional
        Heating base temperature (will be optimized if None)
    cooling_base : float, optional
        Cooling base temperature (will be optimized if None)
    
    Returns:
    --------
    normalized_demand : array
        Weather-normalized demand
    model_info : dict
        Information about the fitted model
    """
    # Find optimal base temperatures if not provided
    if heating_base is None or cooling_base is None:
        (heating_base, cooling_base), r2 = find_optimal_base_temperatures(demand, temperature)
    
    # Calculate degree days
    hdd, cdd = calculate_degree_days(temperature, heating_base, cooling_base)
    
    # Fit regression model: demand = baseline + heating_coeff * HDD + cooling_coeff * CDD
    X = np.column_stack([hdd, cdd, np.ones(len(hdd))])
    model = LinearRegression(fit_intercept=False).fit(X, demand)
    
    # Calculate reference conditions (mild weather with minimal heating/cooling)
    reference_temp = 20.0  # 20°C as comfortable reference
    ref_hdd, ref_cdd = calculate_degree_days([reference_temp], heating_base, cooling_base)
    reference_conditions = np.array([[ref_hdd[0], ref_cdd[0], 1.0]])
    
    # Predict demand under reference weather conditions
    baseline_demand = model.predict(reference_conditions)[0]
    
    # Weather effects in actual data
    weather_effects = model.predict(X) - baseline_demand
    
    # Normalized demand removes weather effects
    normalized_demand = demand - weather_effects
    
    model_info = {
        'heating_base': heating_base,
        'cooling_base': cooling_base,
        'r2_score': model.score(X, demand),
        'coefficients': {
            'heating_slope': model.coef_[0],
            'cooling_slope': model.coef_[1], 
            'baseline': model.coef_[2]
        },
        'reference_temp': reference_temp
    }
    
    return normalized_demand, model_info

def estimate_btm_time_series_improved(data, window_days=30):
    """
    Improved BTM solar estimation using proper weather normalization and time series analysis
    
    Parameters:
    -----------
    data : DataFrame
        Input data with columns: DateTime, demand, temperature_2m, surface_solar_radiation_downwards, is_solar_hours
    window_days : int
        Rolling window size in days for trend analysis
    
    Returns:
    --------
    DataFrame with added columns for BTM estimation
    """
    results = data.copy()
    window_hours = window_days * 24
    
    # Separate solar and non-solar hour data
    solar_data = data[data['is_solar_hours'] == 1].copy()
    non_solar_data = data[data['is_solar_hours'] == 0].copy()
    
    print(f"Processing {len(solar_data)} solar hours and {len(non_solar_data)} non-solar hours")
    
    # Step 1: Weather normalize both datasets using regression method
    print("Step 1: Weather normalizing solar hour demand...")
    solar_normalized, solar_model_info = weather_normalize_demand_regression(
        solar_data['demand'].values, 
        solar_data['temperature_2m'].values
    )
    solar_data['normalized_demand'] = solar_normalized
    
    print("Step 1: Weather normalizing non-solar hour demand...")
    non_solar_normalized, non_solar_model_info = weather_normalize_demand_regression(
        non_solar_data['demand'].values, 
        non_solar_data['temperature_2m'].values
    )
    non_solar_data['normalized_demand'] = non_solar_normalized
    
    print(f"Solar hours model R²: {solar_model_info['r2_score']:.3f}")
    print(f"Non-solar hours model R²: {non_solar_model_info['r2_score']:.3f}")
    
    # Step 2: Calculate rolling trends for normalized demand
    print("Step 2: Calculating demand trends...")
    solar_indexed = solar_data.set_index('DateTime')
    non_solar_indexed = non_solar_data.set_index('DateTime')
    
    # Use time-based rolling window
    solar_trend = solar_indexed['normalized_demand'].rolling(
        window=f'{window_days}D', min_periods=max(1, window_hours//4)
    ).mean()
    
    non_solar_trend = non_solar_indexed['normalized_demand'].rolling(
        window=f'{window_days}D', min_periods=max(1, window_hours//4)
    ).mean()
    
    # Step 3: Merge trends back to main dataset
    results = results.set_index('DateTime')
    results['solar_trend'] = solar_trend
    results['non_solar_trend'] = non_solar_trend
    results = results.reset_index()
    
    # Forward fill and backward fill missing values
    results['solar_trend'] = results['solar_trend'].fillna(method='ffill').fillna(method='bfill')
    results['non_solar_trend'] = results['non_solar_trend'].fillna(method='ffill').fillna(method='bfill')
    
    # Step 4: Establish baseline relationship using early data (first year)
    print("Step 3: Establishing baseline solar/non-solar relationship...")
    early_data_mask = results['DateTime'] <= (results['DateTime'].min() + pd.Timedelta(days=365))
    early_data = results[early_data_mask]
    
    # Calculate baseline ratio with robust statistics (median to avoid outliers)
    valid_early = early_data.dropna(subset=['solar_trend', 'non_solar_trend'])
    if len(valid_early) > 100:
        baseline_ratio = (valid_early['solar_trend'] / valid_early['non_solar_trend']).median()
    else:
        baseline_ratio = 1.0  # fallback
    
    print(f"Baseline solar/non-solar ratio: {baseline_ratio:.3f}")
    
    # Step 5: Calculate expected solar demand based on non-solar trends
    results['expected_solar_demand'] = results['non_solar_trend'] * baseline_ratio
    
    # Step 6: Calculate BTM effect as gap between expected and observed trends
    demand_gap = results['expected_solar_demand'] - results['solar_trend']
    btm_effect_base = np.maximum(demand_gap, 0)
    
    # Step 7: Scale by solar radiation availability (improved scaling)
    # Use actual solar radiation relative to maximum observed
    max_solar_radiation = results['surface_solar_radiation_downwards'].quantile(0.95)
    solar_availability = np.clip(
        results['surface_solar_radiation_downwards'] / max_solar_radiation, 
        0, 1
    )
    
    # Apply BTM effect only during solar hours and scale by solar availability
    results['btm_method3'] = 0.0
    solar_mask = results['is_solar_hours'] == 1
    results.loc[solar_mask, 'btm_method3'] = (
        btm_effect_base[solar_mask] * solar_availability[solar_mask]
    )
    
    # Step 8: Apply smoothing to reduce noise
    results['btm_method3'] = results['btm_method3'].rolling(
        window=24, center=True, min_periods=1
    ).mean()
    
    # Ensure non-negative values
    results['btm_method3'] = np.maximum(results['btm_method3'], 0)
    
    # Add model information as attributes
    results.attrs['solar_model_info'] = solar_model_info
    results.attrs['non_solar_model_info'] = non_solar_model_info
    results.attrs['baseline_ratio'] = baseline_ratio
    results.attrs['window_days'] = window_days
    
    print("Step 4: BTM estimation completed successfully!")
    
    return results


# Quick version for comparison
def estimate_btm_simple(data):
    """
    Simplified but improved BTM estimation - quick fix version
    """
    results = data.copy()
    
    # Simple degree-day based weather normalization
    temp = results['temperature_2m'].values
    hdd = np.maximum(18 - temp, 0)  # Heating degree days
    cdd = np.maximum(temp - 24, 0)  # Cooling degree days
    
    # Simple weather adjustment (much better than /20 approach)
    weather_factor = 1 + 0.01 * hdd + 0.015 * cdd  # Based on literature coefficients
    
    # Apply to separate datasets
    solar_data = results[results['is_solar_hours'] == 1].copy()
    non_solar_data = results[results['is_solar_hours'] == 0].copy()
    
    # Weather normalize using the simple but proper method
    solar_normalized = solar_data['demand'] / weather_factor[results['is_solar_hours'] == 1]
    non_solar_normalized = non_solar_data['demand'] / weather_factor[results['is_solar_hours'] == 0]
    
    # Rolling trends (30-day window)
    window = 30 * 24
    
    solar_trend = pd.Series(solar_normalized, index=solar_data.index).rolling(
        window=window, min_periods=window//4
    ).mean()
    
    non_solar_trend = pd.Series(non_solar_normalized, index=non_solar_data.index).rolling(
        window=window, min_periods=window//4
    ).mean()
    
    # Merge back to main dataset
    results['solar_trend'] = np.nan
    results['non_solar_trend'] = np.nan
    results.loc[solar_data.index, 'solar_trend'] = solar_trend
    results.loc[non_solar_data.index, 'non_solar_trend'] = non_solar_trend
    
    # Forward fill
    results['solar_trend'] = results['solar_trend'].fillna(method='ffill').fillna(method='bfill')
    results['non_solar_trend'] = results['non_solar_trend'].fillna(method='ffill').fillna(method='bfill')
    
    # Baseline ratio from first 6 months
    early_mask = results['DateTime'] <= (results['DateTime'].min() + pd.Timedelta(days=180))
    baseline_ratio = (results.loc[early_mask, 'solar_trend'] / 
                     results.loc[early_mask, 'non_solar_trend']).median()
    
    # Expected vs actual
    results['expected_solar_demand'] = results['non_solar_trend'] * baseline_ratio
    demand_gap = results['expected_solar_demand'] - results['solar_trend']
    demand_gap = np.maximum(demand_gap, 0)
    
    # Scale by solar radiation
    max_solar = results['surface_solar_radiation_downwards'].quantile(0.95)
    solar_scale = np.clip(results['surface_solar_radiation_downwards'] / max_solar, 0, 1)
    
    # Apply only during solar hours
    results['btm_method3'] = 0.0
    solar_mask = results['is_solar_hours'] == 1
    results.loc[solar_mask, 'btm_method3'] = demand_gap[solar_mask] * solar_scale[solar_mask]
    
    return results
#results_m3 = estimate_btm_time_series(data_q2_expanded)
#results_m3 = estimate_btm_time_series(data_q2_expanded)
#results_m3 = estimate_btm_time_series_improved(data_q2_expanded)
results_m3 = estimate_btm_simple(data_q2_expanded)

print("BTM Solar Estimation Summary (Method 3):")
print(results_m3.groupby('year')['btm_method3'].sum().round(2))
```

## Comprehensive BTM Solar Analysis

### Combine Methods and Calculate True Demand

```{python}
#| label: combine-methods
# Combine results from all three methods
final_results = data_q2_expanded.copy()
final_results['btm_method1'] = results_m1['btm_method1']
final_results['btm_method2'] = results_m2['btm_method2']
final_results['btm_method3'] = results_m3['btm_method3']

# Calculate ensemble estimate (equal weighting for the two primary methods)
#final_results['btm_ensemble'] = (
#    0.45 * final_results['btm_method1'] + 
#    0.45 * final_results['btm_method2'] + 
#    0.10 * final_results['btm_method3']
#)
#
# Current: 45% Method 1 + 45% Method 2 + 10% Method 3
# Recommended: 50% Method 1 + 40% Method 2 + 10% Method 3
# Quick validation: BTM should correlate with solar radiation

final_results['btm_ensemble'] = (
    0.90 * final_results['btm_method1'] +    # Random Forest (most robust)
    0.05 * final_results['btm_method2'] +    # Ridge (simpler, less overfitting)
    0.05 * final_results['btm_method3']      # Time series (validation only)
)

# Quick sanity check for each BTM method individually
print("=== QUICK BTM SANITY CHECKS ===")
print("Monthly BTM-Solar Radiation Correlation (should be > 0.7)")
print("-" * 55)

methods = ['btm_method1', 'btm_method2', 'btm_method3', 'btm_ensemble']

for method in methods:
    if method in final_results.columns:
        # Calculate monthly averages for BTM and solar radiation
        monthly_stats = final_results.groupby(final_results['DateTime'].dt.month).agg({
            method: 'mean',
            'surface_solar_radiation_downwards': 'mean'
        })
        
        # Calculate correlation between monthly BTM and solar radiation
        correlation = monthly_stats[method].corr(monthly_stats['surface_solar_radiation_downwards'])
        
        # Determine status
        if correlation > 0.7:
            status = "✓ EXCELLENT"
        elif correlation > 0.5:
            status = "✓ GOOD"
        elif correlation > 0.3:
            status = "⚠ WEAK"
        else:
            status = "✗ POOR"
        
        print(f"{method:<15}: {correlation:.3f} {status}")

print("\nInterpretation:")
print("- > 0.7: Strong seasonal pattern (BTM high in summer, low in winter)")
print("- 0.5-0.7: Moderate seasonal pattern")
print("- 0.3-0.5: Weak seasonal pattern") 
print("- < 0.3: Poor/unrealistic seasonal pattern")


# Quick validation: BTM should correlate with solar radiation
correlation = final_results.groupby(final_results['DateTime'].dt.month).agg({
    'btm_ensemble': 'mean',
    'surface_solar_radiation_downwards': 'mean'
}).corr().iloc[0,1]

print(f"BTM-Solar correlation by month: {correlation:.3f}")
# Should be > 0.7 for reasonable estimates

# Calculate final "true demand"
final_results['true_demand'] = final_results['demand'] + final_results['btm_ensemble']

print("=== BTM Solar Estimation Comparison  ===")
btm_comparison = final_results.groupby('year')[
    ['btm_method1', 'btm_method2', 'btm_method3', 'btm_ensemble']
].sum().round(2)

print("Annual BTM Solar Generation Estimates (GWh):")
print(btm_comparison / 1000)
```

## Answering the Guiding Questions

### Question 2.1: How can we isolate the effect of BTM solar generation on observed demand?

**Answer:** We isolate the BTM solar effect by modeling the *expected* electricity demand during solar hours based on data from *non-solar hours*. This approach creates a counterfactual baseline of what demand would look like without any BTM solar. The BTM effect is then quantified as the **gap** between this predicted baseline and the actual observed demand. We use three distinct modeling techniques (Random Forest, Ridge Regression, and Time Series Decomposition) to create this baseline, and combine them into a robust ensemble to ensure our results are not dependent on a single model's assumptions.

### Question 2.2: Can you estimate what the demand would have been during solar hours if there were no rooftop solar?

**Answer:** Yes. The `true_demand` column in our final dataset represents this estimation. By adding our calculated `btm_ensemble` generation back to the `demand` that was observed by the grid, we reconstruct the total electricity consumption.

```{python}
#| label: answer-q2
# Plot a sample day to illustrate the concept
sample_day = final_results[final_results['DateTime'].dt.date == pd.to_datetime('2023-07-15').date()].copy()

fig = go.Figure()
fig.add_trace(go.Scatter(x=sample_day['hour'], y=sample_day['demand'], name='Observed Demand', mode='lines', line=dict(color='blue', width=2)))
fig.add_trace(go.Scatter(x=sample_day['hour'], y=sample_day['true_demand'], name='Estimated True Demand (Counterfactual)', mode='lines', line=dict(color='red', dash='dash')))
fig.add_trace(go.Bar(x=sample_day['hour'], y=sample_day['btm_ensemble'], name='Estimated BTM Solar', marker_color='green', opacity=0.5))

fig.update_layout(
    title='Counterfactual Demand on a Sunny Day (July 15, 2023)',
    xaxis_title='Hour of Day',
    yaxis_title='Demand / Generation (MWh)',
    legend_title='Metric'
)
fig.show()
```

### Question 2.3: Estimate the difference between projected demand and observed demand.

**Answer:** The difference is our `btm_ensemble` estimate. The table below summarizes this difference annually. The gap has grown substantially, from an estimated 1,880 GWh in 2020 to over 10,000 GWh in 2024.

```{python}
#| label: answer-q3
annual_gaps = final_results.groupby('year').agg(
    demand_gap_gwh=('btm_ensemble', lambda x: x.sum() / 1000),
    avg_hourly_gap_mwh=('btm_ensemble', 'mean'),
    max_hourly_gap_mwh=('btm_ensemble', 'max')
).round(1)

print("Annual Difference (Projected - Observed Demand):")
print(annual_gaps)
```

### Question 2.4: How has BTM solar generation evolved from 2020 to the present?

**Answer:** BTM solar generation has evolved dramatically, showing exponential growth. Our analysis estimates that BTM generation has increased by over 400% between 2020 and 2024. It now represents a significant portion of Germany's total solar output, being equivalent to over 20% of the grid-scale solar generation in 2024.

```{python}
#| label: answer-q4
btm_evolution = final_results.groupby('year').agg(
    btm_total_gwh=('btm_ensemble', lambda x: x.sum() / 1000),
    grid_solar_gwh=('power', lambda x: x.sum() / 1000)
)
btm_evolution['btm_yoy_growth'] = btm_evolution['btm_total_gwh'].pct_change() * 100
btm_evolution['btm_as_pct_of_grid'] = (btm_evolution['btm_total_gwh'] / btm_evolution['grid_solar_gwh']) * 100

print("Evolution of BTM Solar Generation (2020-2024):")
print(btm_evolution.round(1))

# Plot the evolution
fig = make_subplots(specs=[[{"secondary_y": True}]])
fig.add_trace(go.Bar(x=btm_evolution.index, y=btm_evolution['grid_solar_gwh'], name='Grid Solar (GWh)', marker_color='lightblue'), secondary_y=False)
fig.add_trace(go.Bar(x=btm_evolution.index, y=btm_evolution['btm_total_gwh'], name='BTM Solar (GWh)', marker_color='darkgreen'), secondary_y=False)
fig.add_trace(go.Scatter(x=btm_evolution.index, y=btm_evolution['btm_as_pct_of_grid'], name='BTM as % of Grid', mode='lines+markers', line=dict(color='red')), secondary_y=True)
fig.update_layout(title_text='Evolution of BTM vs. Grid Solar Generation')
fig.update_yaxes(title_text="Total Generation (GWh)", secondary_y=False)
fig.update_yaxes(title_text="BTM as % of Grid Solar", secondary_y=True)
fig.show()
```

### What is the year-over-year growth in *true* demand?

**Answer:** After accounting for the BTM solar effect, we can calculate the growth in Germany's *true* electricity demand. The analysis shows that while observed grid demand has appeared stagnant or even declined in some years, the true underlying demand has been growing consistently. The true demand grew by approximately 1.5% from 2022 to 2023, a period where observed demand appeared to shrink by -0.8%. This highlights the critical importance of this analysis: failing to account for BTM solar gives a misleading picture of energy consumption trends.

```{python}
#| label: answer-q5
# Calculate true demand growth
annual_demand = final_results.groupby('year').agg(
    observed_demand_twh=('demand', lambda x: x.sum() / 1e6),
    true_demand_twh=('true_demand', lambda x: x.sum() / 1e6)
)

annual_demand['observed_growth_pct'] = annual_demand['observed_demand_twh'].pct_change() * 100
annual_demand['true_growth_pct'] = annual_demand['true_demand_twh'].pct_change() * 100

print("Year-over-Year Growth: Observed vs. True Demand")
print(annual_demand.round(2))

# Plot the comparison
fig = go.Figure()
fig.add_trace(go.Bar(x=annual_demand.index, y=annual_demand['observed_growth_pct'], name='Observed Demand Growth (%)'))
fig.add_trace(go.Bar(x=annual_demand.index, y=annual_demand['true_growth_pct'], name='True Demand Growth (%)'))
fig.update_layout(
    title='YoY Growth: Observed vs. True Demand',
    xaxis_title='Year',
    yaxis_title='Annual Growth (%)',
    barmode='group'
)
fig.show()
```
